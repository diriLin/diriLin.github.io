[{"title":"CUHK-开学半个月杂谈","url":"/Gossip/CUHK%E5%BC%80%E5%AD%A6%E5%8D%8A%E4%B8%AA%E6%9C%88%E6%9D%82%E8%B0%88/","content":"入学已经有一段时间了，周日的晚上突然不想做任何事情，只想胡说八道一通，写点流水账。\n生活现在基本是1097，早上8点多起床的时候并没有那种神清气爽的感觉，再摆一摆就是9点了，然后找点吃的，到lab基本上10点；晚上9点半左右回到家，12点左右睡觉。\n\n我的工位\n\n乍一看整个flow还是不错的，但其实我是根本不会生活。具体的表现包括：\n\n1097. 其实我们lab还是非常宽松的，就算是工作日也有老哥不怎么来。我周末来lab的原因就是我实在是太空虚了，如果不来lab的话我能做些什么呢？我什么都不会。还有就是，CUHK的部分食堂真的物美价廉，省钱的不二之选。因此所谓1097不是压榨的结果，而是在生活上极度失败的人对自己的惩罚。\n1097. 工作日下班之后，回家洗澡，完事又不知道该做什么了，一个“局部最优”的选择是躺在床上一直刷手机。\n玩游戏么，电子阳痿了，即使是gal，我也有些倦了\n看番么，遇到好看的或者是已经看过的，我可能会忍不住连续地看下去，进而破坏整个flow\n\n\n\n不会享受生活确实是我的一个非常严重的缺陷。如果不能让自己变得幸福快乐起来，只是现在一样一味痛苦然后过着单调生活的话，工作也没有意义了，把自己的爱能传达给亲人爱人什么也更是空谈。改善的话，我想一是找个踢球的组织，周末运动一下；然后想学一门乐器（吉他我不知道好不好？）陶冶一下情操。\n学习&amp;工作现在我打这个比赛感觉虽然是初学者的玩具，但整个过程已经有点日后工作的雏形了。根据我对师兄的观察，我觉得工作的流程应该是：\n\n根据赛题（任务）的性质，使用以往的工具建立workflow\n\n不同来源的第三方工具之间数据接口的调整是一项比较重要但又很那啥的工作。\n\n\n对中间结果（比如像overflow这样的数值，比如place的图像）进行分析，观察现有workflow的问题\n\n问题是因为workflow不合理？还是因为workflow的某个环节使用的工具不太符合任务性质的要求？\n考虑是会先考虑workflow的合理性问题，比如从图像上看出很需要调整macro block的朝向，但是现在的workflow没有rotate的功能这种非常明显的问题，但实际动手一般从对某个环节的工具的级别入手，微调或者更换。\n\n\n\n这个过程说得简单，但是我完全一点都做不好（至少是现在）：\n\n使用以往的工具建立workflow，就需要对工具有比较多的了解，要读很多篇文章，知道哪些环节可以使用哪些工具，知道他们的性能和优缺点；只看论文不实际下载下来跑跑调调，也不可能对这个工具有深刻的印象和认识。\n\n根据赛题/数据集性质选用工具、从中间结果分析代码或者工具workflow级别的问题，这些都极度需要丰富的工程经验才能像师兄这样非常流畅丝滑快速地做完\n\n我实在是被师兄迅速分析并给出建言的能力震撼到了。这种能力也需要很多的工作经历和努力，才能获得，像我现在这样得过且过是不太行的。但没必要也不可能在入学的时候就能达到师兄的水平，慢慢来吧。\n\n\n\n除此之外，我的沟通能力也是一团糟：\n\n首先英语就是烂的不行。我参加了一个杜伦大学炼丹AP的seminar，说实话只能大概的听懂，语速我听着是不太能跟上的，只能是听+猜+看图，更别说发言讨论了\n\n万幸我的老板是个香港local，粤语交流是完全没问题\n\n\n还有我在开会或者面对面交流的沟通过程中的表达问题\n\n我认为这个问题的根源首先在于我对physical design的过程并不是每个环节都非常了解，有些环节我只知道个皮毛。这就导致我没有对整个flow的分析能力，此外当师兄谈到一些我不了解的内容时，听都听不懂，更别说表达自己的意见了。\n我自卑的心态也有非常大的问题。经过高二高三的挫折再加上复读一年的折磨，然后又在哈深呆了4年，我现在处于生理性地没事就开始在心里骂自己傻逼的状态；然后我的能力确实也不如师兄和同年进来的同学，这些确实地造成了我极度自卑的心态。这对我自信地表达清楚产生了非常大的影响。\n还有就是没有梳理自己工作内容的习惯，因此报告自己的工作的时候不够体系化。\n\n\n\n因此就从我当前所站的位置而言，我是极度需要系统地进行学习的状态。我现在已经是这么烂，没有办法了，只能是对上面的问题一个一个地自我驱动去攻克它们，希望四年之后能成为无论是工作上还是生活上都能处理得很好的人吧。\n工作之外的杂事在入学的事情上面我要疯狂地称赞CUHK Graduate School，实在是我见过的最低效的行政机构：\n\n没有ddl概念。学生都是傻逼都是牛马，graduate school不把学生当人其实无所谓的，但是它的逆天之处在于，在和CUHK的其他行政机构（比如Dept. CSE，比如Postgraduate Hall）的沟通合作中，也可以视ddl为无物，CSE的秘书也只能评价：\n\nBased on the reply from the GS, it seems that they do not have any approximate processing timeframe.\n\n\n沟通敷衍了事。我在GS office和办公室人员使用粤语进行沟通，力求表达清晰提高效率，但这些人居然可以强行扳回来用普通话敷衍我。这不是说用普通话就是敷衍，而是说，这些工作人员认为用普通话就可以因为他们是港人所以说不清楚，那么吞吞吐吐含混不清也就是可以接受的了。我真没想到这么骚的推搪方式。\n\n\n","categories":["Gossip"]},{"title":"ABCDPlace","url":"/Paper-reading/ABCDPlace/","content":"\n论文以及图片来源：ABCDPlace: Accelerated Batch-Based Concurrent Detailed Placement on Multithreaded CPUs and GPUs | IEEE Journals &amp; Magazine | IEEE Xplore\n\n摘要Placement可以分为GP, legalization以及DP(Detail Placement)三个部分，其中DP可能被反复invoke。ABCDPlace主要对DP的并行化提出了一些改进。\nPRELIMINARIES优化的目标是HPWL，参见Logic to Layout Week 5 | diri! (diri-lin.top).\n提到了三种用于DP的方法，分别是：\n\n独立集匹配（Independent Set Matching）。独立集中的任意两点在图上不相邻，即cells之间没有边连接，因此在优化HPWL时可以不考虑这些cells之间的关系。在独立集中寻找两个cells进行移动，仅需要考虑这些cells相连的nets的HPWL变化。寻找独立集之后可以得到一个二部图：\n\n左右两边是独立集中的对应元素（1和1’是同一个cell），而图上的边权重定义为交换这两个cell对HPWL的改进，然后对二部图寻找最大权匹配，根据此匹配交换cells的位置来改进HPWL. \n\n全局交换（Global Swap）。对特定的一个cell，在全局范围内寻找另一个cell使得它们交换之后对HPWL的改进最大，然后交换之。使用启发式的方法来寻找搜索区域。\n\n本地重排（Local Reordering）。在同一个行内，使用滑动窗口来选择个cell，这个cell可以形成个排列，然后在这些排列中寻找其中对HPWL最优的排列。由于复杂度是阶乘级别，不会选得很大。\n\n\n还提到了设计并行算法的时候必须考虑到GPU结构的性质：\n\n下面的算法伪代码中，Parallel kernel可以认为是在一个block内建立了各thread.\n\n在写这个笔记的时候，我对GPU以及CUDA并不详细地了解，因此对这些部分的理解可能有偏差。\n\n独立集匹配Parallel Maximal Independent Set Algorithm作出让步，不寻找最大独立集，而是选择一个cell，求包含这个cell的极大独立集。\n\n在while循环的每一轮中，为点集中的每个点(cell)分配一个线程，这些线程共享存储。如果某轮中点被加入独立集，那么在随机排序中排在后面的点，要么之前就被从中排除了，要么与连接。考察独立集的最终状态：\n\n仅当它与所有点都相邻，才不会出现在中；\n否则其余点必不与相邻，不然它们将在最后一轮被除去。\n\n至于：\n\n“极大”性质\n最多需要轮\n\n的证明，参考[1202.3205] Greedy Sequential Maximal Independent Set and Matching are Parallel on Average (arxiv.org). \nParallel Partitioning With Balanced K-Means Clustering极大独立集会比较大，求解最大权匹配时耗时比较长，因此把它分为个簇，每个簇都是独立集，然后对每个簇和簇的余集求最大权匹配并优化。正常的Kmeans聚类的目标是寻找​个点求下列目标的优化：\n\n\\min\\sum_{i=1}^{K}\\sum_{x\\in S_i}||x-\\mu_i||但这会导致各个簇的大小不均匀，因此采用\n\n\\min\\sum_{i=1}^{K}\\sum_{x\\in S_i}w_i||x-\\mu_i|| \\\\\nw_i^{k+1}\\leftarrow w_i^k\\times(1+0.5\\log(\\max\\{1, |S_i|/s_t\\}))的优化目标，其中是属于中心的簇，是簇的期望大小，通常取128.\nBatch Solving for Linear Assignment Problems对最大权匹配问题，ABCDPlace采取的解法是拍卖算法（算法的思想可以参考最优分配问题-拍卖算法_Anker_Evans的博客）：\n\n拍卖算法分为竞价（bid）和分配（assign）两步。在竞价阶段，各出价人（寻找新位置的cell）互不干扰；在分配阶段，各待分配物品（cell原先占据的位置）互不干扰，因此可以通过建立threads来并行计算，并采取批处理的方式减少反复launch kernel导致overhead过大的问题：\n\n本文采取来控制算法的结束条件。\n全局交换串行的全局交换算法：\n\n时间开销的主要部分是CalcSwapCosts和CollectCands：\n\n并行版本的算法：\n\nCalcSearchBox提供搜索区域，具体来说：\n\nIn the experiment, the search region for one cell is set to one bin, whose width and height are around three-row height.\n\nCalcSwapCosts和CollectCands一起并行执行。具体地说：\n\n对于一个cell（比如蓝色的1）建立多个threads，每个thread选择一个candidate并计算交换改进，为下一步FindBestCand做准备。\n最后的ApplyCand可能存在依赖关系，比如a/b都决定和c交换，因此不能够并行的执行，但是这一步并不是性能的瓶颈。\n本地重排\n本文通过三个方面来提高本地重排算法的并行度：\n\n并行枚举：长度为的滑动窗口内，并行计算个排列的HPWL（或者改进）。由于不大，这并不能在GPU上很好地提升速度。\n并行窗口：如上图Step1所示，多个窗口内的重排互不相关，因此可以进行并行。\n独立行组：如上图(b)所示，row1和row4没有cell直接被net连接，将他们放到一个组内。\n\n","categories":["Paper-reading"],"tags":["EDA"]},{"title":"Logic to Layout Week 3","url":"/Learning/Logic-to-Layout-Week-3/","content":"2-level synthesis2-level综合优化指：\n\nsum of product的形式\n最少的与门\n满足以上条件，最少的输入(literals)\n\n\n策略\n\n很难找到最优解-&gt;寻找次优解\n迭代优化\n\n最优解的性质：\n\nBest solution is composed of cover of primes\nprimes指卡诺图中尽可能大的cube\n\n\nirredundant\n\n也按照这些性质找次优解。\nthe Reduce-Expand-Irredundant Optimization Loop初始状态：\n\n表中的每一项对应卡诺图的一个由1组成的cube.\nExpand step:将每一个不是prime的cube扩大成prime：\n\nQ cube: 0*10-&gt;**10S cube: 1101-&gt;**01R cube: 1101-&gt;1**1\nIrredundant step:去掉那些冗余的prime，来满足irredundant.\n\nR cube是冗余的，所以被去掉了。\n然后开始Reduce-Expand-Irredundant Optimization Loop.Reduce step:\n\n\n尽可能收缩primes，但不要使得有1未被覆盖\n这虽然使得我们不满足primes的要求，但提供了向其他方向优化的可能\n\n总结：\n\n\nLoop的起点：primes &amp; irredundant\nReduce后：not primes &amp; irredundant\nExpand后：primes &amp; redundant\nIrredundant后：primes &amp; irredundant\n\n然后是下一个loop, 直至收敛。\n细说Expand这里使用的数据结构是cube list:\n\n对于给定的函数F, 首先求补：\n\n然后形成一张表格，其中行是要待扩展的cube的文字，而列代表F’的各product项：\n一个格子，如果它的行所代表的文字的反文字出现在它的列代表的项中，那么它的值为1，否则为0:\n\n扩展，就是选择某些行，这些行的product就是比原来更大的cube\n比如上图我选取了w’x，这就是一个包含原来的w’xyz’的更大的cube\n\n\n选哪些行？\n上图中，假设我只选了w’，那么w’就会覆盖到x’z的一部分，那么这个expand是错误的\n我们也可以看到表中的w’行x’z列是0，也就是说，w’和F’中的x’z项没有冲突\n\n\n假设选w’x，这是一个合理的expand，因为x使得这个product和x’z产生了冲突，从而w’x和F’中的所有product都产生了冲突\n结论：选择最小的行集合，使得每一列都至少有一个1.\n这就将原问题转化为了集合覆盖问题\n\n\n\n\n\nMultilevel synthesis课程的这一章节提到的优化目标是Total literal count.\n\nYes, delays matter too, but for this class, only focus on logic complexity.\n\n数据结构-布尔逻辑网络：分为三个部分\n\n原始输入\n原始输出\n2-level SOP作为中间节点\n\n\n操作：\n\n简化网络节点，此前提到的2-level synthesis\n删除网络节点，将太小的节点删除\n增加网络节点，将节点的“公因式”提取出来(factoring)(重点)\n\nFactoringAlgebraic Model的想法是，只考虑布尔代数和实数运算中相同的定理和性质：\n\n可以看到，不一致的部分涉及a’，因此factoring的一条重要的原则是，变量的补要和变量视为无关。Factoring将待分解的函数F分解为：\n\n并不严格需要余数(remainder)为0，因为即使不为0也可以与其他代数式共享divisor. Algebraic Division Algorithm的伪代码：\n\n要点：\n\ncube，就是sum of product里面的product\n指将视为cube的集合\n\n一个例子：F=axc+axd+axe+bc+bd+de, D=ax+b, 求F/D\n\n\n表格的第一列是F的cubes\n从第二列开始for循环\nD第一个cube是ax，F的cubes中前三个含有ax，去掉之后得到C=Q=c+d+e\nD第二个cube是b，F的cubes中后三个含有b，去掉之后得到C=c+d, 因此Q=Q\\cap C=c+d\n\n\nR=F-QD=axe+de\n\n注意事项：求F/D时，输入F不可以有冗余的cubes，因为这可能会导致错误，举个例子：\n\nF=a+ab+bc, D=a\n运算结果：F/D=1+b, remainder=bc, 其实好像也能成立，但是Algebraic model中没有1+b这种操作，因为在布尔代数和实数中，这种操作的结果不一定相同。\n\n这种factoring可以带来的简化效果是这样的：\n\n接下来讨论怎么寻找只有1个cube的divisors和multiple-cube divisors.\nKernels and co-kernelskernel的定义：\n\n\nc是单个product(single cube)\nk是cube-free two-level SOP forms\ncube-free的意思是指k不能被分解为这种形式\n\n\n满足的k被称为kernel，而c被称为co-kernel\nF的kernels的集合记作K(F)\nco-kernel就是上面说的只有1个cube的divisors\n\n\n\nBrayton &amp; McMullen Theorem\n\\text{布尔代数式F, G有共同的multi-cube divisor d}\\iff \\text{存在}k_1\\in K(F), k_2\\in K(G) \\text{使得}d=k_1\\cap k_2\\text{且}d\\text{含有}2\\text{个以上的cubes}交运算将SOP看成cubes的集合。因此我们只需要在两个代数式的kernels的交集中寻找multiple-cube divisors即可：\n\nkernels的求解可以递归地进行，理由如下，假设, 那么\n\nF=c_1\\cdot k_1+r_1 \\\\\nk_1=c_2\\cdot k_2+r_2\\\\\nF=c_1\\cdot (c_2\\cdot k_2+r_2)+r_1=c_1c_2\\cdot k_2+(c_1r_2+r_1)因此也是F的kernel. \nBrayton et al.的另一个有用结论是：布尔表达式的co-kernels与表达式2个以上的cubes的交运算结果对应，其中“交运算”指将cube视为literals的集合。举例：F=ace+bce+de+g, ，那么ce是潜在的co-kernel.\n从这两个结论出发，得到求cube-free SOP expression F的kernels集合K(F)的算法伪代码：\n\n","categories":["Learning"],"tags":["EDA"]},{"title":"Logic to Layout Week 2","url":"/Learning/Logic-to-Layout-Week-2/","content":"今天是去南京旅游的第三天，前两天走了平均走了35000+步，今天早上就权当休息了，不出去走，来写写博客。\nBinary Decision Diagrams(二分决策图，BDDs)一种比Cube List更powerful的数据结构，用来表达多输入多输出的电路。常用的是Reduced Ordered Binary Decision Diagram(ROBDD，课程后面有很多ROBDD和BDD的混用，实际指代的都是ROBDD)：\n\nOrdered\n\n名字的第二个单词，意思是这个图的根节点到叶子节点（函数值）的决策过程中出现的变量符合一个给定的顺序，可以有某些变量缺省。\n\n\nCanonical form(规范型)\n\n对一个函数来说，给定同样的变量顺序，ROBDD给出的图应该是相同的。\n\n\n\n\nBDD示例，并没有Reduced and ordered\n\nOrdering视频说的是No universal solution，给出了一些办法：\n\nCharacterization: know which problems never make nice BDDs (eg, multipliers)\nDynamic ordering: let the BDD software package pick the order… on the fly（这是认真的吗？）\n启发式的规则：相关的输入变量应该尽可能地放在一起\n给出了一个例子：如果先算a再算b，由于a1, a2, a3之间没有关系，决策树会完全地展开，这导致BDD很庞大。\n\n\n\n但是左边的图为什么可以这么reduced? 接下来将ROBDD的build up.\n建立ROBDD的方法有两种方法，第一种是从BDT简化得来：\nReduce\n二分决策树BDT\n\nBDT就不必多说了，要注意必须是ordered. 然后做以下几类reduction: \n\n合并0节点和1节点；\n合并同构(isomorphic)节点，其中同构是指：\n节点代表的变量相同；\n它们的低指针指向相同的child, 高指针也一样；两个x的指针指向相同的children\n\n\n删除冗余的节点x无论取什么值对下一步决策没影响，因此可以直接删去\n\n\n\n迭代进行以上操作，直至图不能够再reduce. 但实际不这么建立ROBDD，因为光是建立BDT就已经是指数时间复杂度。\n自底而上，gate by gate呃呃，这个课程说大概是这么干的，却没有说具体怎么做，比如得到T1和T2之后具体怎么进行Or的操作。我参考了jacob的文章，他以为例（变量顺序是）：\n\n“隐式扩展”指的是对齐两边的变量，之前在reduce的时候讲过要删除冗余的变量，此处用相反的方法加回去，先检查：然后是：对齐之后，同时在两个图上进行遍历，比如上图就连续两次决策为0，发现结果都为0；然后决策为0-1，得到一个结果是0，一个结果是1，那么就对这两个常数结果进行运算：\n\n这就是总体的思路。具体的操作，jacob总结为：\n\n并行地遍历两个图，在两个给定的图中始终同时沿着0边或1边移动；\n当一个变量在一个图中存在，而不在另一个图中时，我们就像它存在并且有相同的high和low子节点一样继续进行（前面提到隐式地扩展，即实际上并不会创建节点，而是直接递归调用下去，后面的代码分析中可以看到，这里采用扩展结点是为了方便说明）；\n当到达两个图的终端结点0或1时，对这些常量应用布尔运算并返回相应的常量;\n如果对high和low子节点的运算返回相同的节点，不构造一个新节点，而只是返回在树中已经获得的单个节点。避免冗余；\n如果将要构造一个已经在结果图中某处的节点(也就是说，具有相同的变量标签和相同的后续节点)，不要创建一个新的副本，而只是返回已经存在的节点。\n\nSATSAT问题就是说，对于一个布尔表达式，是否有一组对变量的赋值使布尔表达式的值为1. 当然可以用BDD的方法来解，但是BDD相当于求出了每一组输入的函数值，这对SAT来说太多了；需要一种新的数据结构和快速的解法来应付这个问题。\n有很多问题可以转化为SAT问题，课程给出的例子是判断两个布尔函数F和G是否是等价的：\n\nConjunctive Normal Form(合取范式，CNF)数理逻辑的东西都忘好多了：\n\n若p是一个原子公式(atom)，则p和p’称为文字(literal)\n文字的析取被称为子句(clause)\n子句的合取被称为合取范式(CNF)\n\nCNF的好处在于，如果有一个子句的值为0，那就可以判断整个表达式的值不可能为1了，需要寻找其他的赋值来满足。\ngate by gate建立布尔函数的CNF这里的CNF里面的文字并不全是布尔函数的输入，也包含中间wire的值和输出，因此我觉得课程把它叫做布尔函数的CNF不是特别合适，实际的意思是可以用来进行下面的SAT问题BCP求解的CNF输入形式。\nGate consistency function(逻辑门一致性函数)上面提到的CNF含有中间wire的值和输出，它们本来应该是输入（或者某门的输入）的函数，这里把它们变成CNF的变量，其实是将它们和输入（或者某门的输入）的相关性用别的方式去表达了，而这个“别的方式”，就是Gate consistency function. 比如对于与非门，它的Gate consistency function是\n\n\\varPhi_d=(d==\\overline{ab})=(a+d)(b+d)(\\overline{a}+\\overline{b}+\\overline{d})要求这个函数的值为1，也就是要求，确实能代表这个逻辑门的输出。\n课程提出的CNF的形式是：\n\n\\text{CNF}=(\\text{output var})\\prod_{k\\in{\\text{gates}}}\\varPhi_k要使原来的布尔函数可满足，首先输出变量肯定为1，其次，所有逻辑门的一致性函数都为1，这样输出变量和中间变量才能代表上游的逻辑门的运算结果；反过来，CNF的SAT的一组解，将里面的中间变量和输出变量去掉，剩余的输入变量也必是原函数SAT问题的解。因此：\n“原函数的SAT问题有无解”与“其CNF的SAT问题有无解”是等价的。\n课程也给出了一些常见的CNF转化公式：\n\nBoolean Constraint Propagation(布尔约束传播，BCP)递归地求解CNF的SAT问题。递归基：\n\nSAT: 找到一组赋值，使得这个CNF的子句全是1\nUNSAT: 存在（与SAT的）矛盾(conflict)，至少有一个子句的值为0\n\n否则至少有一个子句的值未知。我们需要选择一个未赋值的变量进行赋值，使得问题的规模变小：\n\n如果存在单文子的子句(unit)，则对这个变量赋值使unit的值为1\n否则选一个未赋值变量，赋值为0或者1\n\n然后进行DFS搜索，当求解到UNSAT的时候，需要进行回退，回退必须包含一次上述情况2的取消，因为情况1的赋值是必然的，并没有剪除可能的分支。如果回退到了问题的根节点，则说明SAT无解。\n对于用gate by gate建立的CNF，显然第一个unit就是输出变量。，而且下游的逻辑门输出必然在上游的变量之前变成unit，本质是从输出向输入方向倒退的搜索过程。\n明天去到武汉就没电脑喽，就写到这里。\n","categories":["Learning"],"tags":["EDA"]},{"title":"Logic to Layout Week 4","url":"/Learning/Logic-to-Layout-Week-4/","content":"Divisor ExtractionWeek 4 先接着讲如何mechanically do factoring.\nsingle-cube extractioncube-literal matrix: \n\n每一行是布尔代数式的一个cube(product term)\n每一列是一个literal\n对每一个位置，如果列指出的literal出现在行指出的cube中，那么该位置为1\n\n\nrectangle: 形如(R, C)\n\nR是行的集合，C是列的集合\n如果这些行和列的交汇处的值都为1，则称(R, C)是一个rectangle，而是一个合法的single-cube divisor\n对一个rectangle，如果不能再增加行或者列，则称其为prime rectangle\n一个rectangle节省的literals: \n\\text{literals saved} = (C-1)\\times \\sum_{rows\\ r}Weight(r) -C其中是r指出的product在要extract的网络中出现的次数。\n\nmultiple-cube extraction类似地，我们有co-kernel—cube matrix: \n\n每一行是一个(function, co-kernel)对\n每一列是kernel的一个cube\n对每一个位置，如果列指出的cube出现在行指出的co-kernel对应的kernel中，那么该位置为1\n\n\n对rectangle(R, C), 是一个合法的multiple-cube divisor. 然后节省的literals的计算公式也被更新：\n\nHow to Find a Prime Rectangle in Matrix?说得非常地粗糙，给我整迷糊了，大意是使用贪心算法来求次优解，先寻找一个最佳的单行结果，然后每次加行加列：\n\n优化的效果接近最优解，而计算效率远高于计算最优解的算法：\n\n（感谢大学城图书馆）后来我找到了rudell的博士论文的原文：\n\n先解释一下一些记号：\n\n 就是行集和列集组成的rectangle\n co-kernel — cube matrix\n 优化目标函数，参数是行集和列集，即，返回一个值\n\n在这个问题中，就是这个rectangle的multiple-cube divisor所节省的literals数量\n它的说法是\n\n is itself defined in terms of the row and column weights ( and ) and the value matrix ().\n\n其中 and 和就是上面的Weight和Value\n\n\n\n\nping_pong_row就是一个从最优的单行开始的优化过程。注意：xxx_row和xxx_col仅存在方向上的不同。先把这个过程的伪代码放上来：\n\n一开始先找出v最大的单行：\n\n\n\n然后先调用一次greedy_row，从一个单行rectangle开始，进行贪心扩展：\n\n每次加一个行，使加进去之后的v最大：\n\n\n\n注意：\n\n加行之后可能使列数减少\n因此，加进去之后的最大v也有可能比之前更小，需要一个变量来记录最大值，也就是\n\n直到，greedy_row返回加行过程中的最佳结果。\n然后开始循环，循环过程中依然是用来记录最佳的行集和列集：\n\n列集中选一个最佳的单列，然后调用greedy_col进行扩展\n如果这次扩展没有得到更佳的结果，跳出循环；\n否则更新\n\n\n行集中选一个最佳的单行，然后调用greedy_row进行扩展\n如果这次扩展没有得到更佳的结果，跳出循环；\n否则更新，进行下一次循环\n\n\n\nDon’t cares(DCs)Don’t cares的意思就是：\n\n右边卡诺图的这些d，我们don’t care他们的取值，因此我们可以任意地将他们设置为1或者0，从而选到更大的prime cube. DCs被分为三类：\n\nSatisfiability don’t cares: SDCs\nControllability don’t cares: CDCs\nObservability don’t cares: ODCs\n\nSatisfiability don’t cares这种DCs指的是network内部节点的输入输出之间不可能出现的组合：\n\n对每个节点的输出，其对应的SDC函数是：\n\n\\text{SDC}_{\\text{output}}=\\text{output}\\oplus\\text{expression of output}比如对X=a+b这个节点，就存在一个相应的SDC函数；然后展开成SOP的形式：；其中：\n\n每一个product为1，就会使得整个SDC函数为1，也就是说和不一致\n那么使这个product为1的这个赋值就是DC，不可能出现这种组合\n比如Xa’b’就指出X=1, a=0, b=0这种取值是不可能的，以此类推\n\n\n\nControllability don’t cares这种DC指的是不可能存在的输入造成的DC，计算的方法是：\n\n其中：\n\n不出现在f中的变量b对要用全称量化进行去除，意思就是，b取任何值的情况下，其他变量的某个赋值都不可能是f的输入（否则如果存在b的一个值使得这个赋值成为可能，就违反了CDC的定义）\n如果要对网络的primary input进行约束（也就是规定哪些输入组合是不可能的），将这些组合放到求和符号里面就好：\n\n\n同样的，化简成SOP的形式之后，每一个cube代表一种DC的输入情况。\nObservability don’t cares这种DC指，在某种输入下，当前节点的输出不会对下一级节点的值产生影响：\n\nPatterns input to node that make network outputs insensitive to output of the node.\n\n既然下一级节点的值对当前节点的输出不敏感，那么当前节点的输出采取什么值也就无所谓了，don’t care.\n对于节点F，ODC的计算公式是：\n\n根据ODC和的定义，这是很自然的。\n","categories":["Learning"],"tags":["EDA"]},{"title":"Logic to Layout Week 5","url":"/Learning/Logic-to-Layout-Week-5/","content":"Logic to Layout从现在开始就要讲Layout的部分了。之前的内容是，怎样设计一个优化的布尔函数，布尔函数是一个逻辑抽象(Logic)，而接下来的学习内容是将布尔函数转化为实际上的电路(layout)。主要分为三个步骤：\n\nTechnology Mapping 将Boolean network model(之前提到的，每个节点是一个2-level SOP的网络)转化为网表(netlist)，网表长这个样子\n其中的连线wire也被称作net, 所以被称为netlist.\n\nPlacement\nRouting\n\n本门课程还讲述时序分析的一些技巧。\nPlacement具体来说，placer的功能是这样的：\n\n输入：netlist\n优化目标：估计的连线长度\n输出：逻辑门的放置\n\n上面提到的Placement和Routing不能合并成一整个流程的原因是，routing的代价太过昂贵了，不能把placement变成其中的一个inside步骤，然后每次优化的时候都执行place &amp; route. placer得到一个不错的gate locations之后，router再在一个固定的gate location上进行连线的优化，这样任务的复杂度就减少了很多。\n因为这门课主要是原理的讲解，所以以下的gate都假定只占据一个网格。\nHalf-Perimeter Wirelength(HPWL)\n这是一个很简陋的下界估计。简单来说，就是围住这个net的最小矩形的半周长。\nIterative Improvement Placer总体的思路是：\n\n随机产生一个placement的初值，来进行迭代优化\n优化的目标，用HPWL代表真实的连线长度期望\n从当前placement出发，产生一个新的placement\n计算的新HPWL\n\n\n在最简单的策略里面：\n\n产生新placement的方法是随机交换两个gates的位置\n对计算的优化：HPWL只需要增量地更新，因为只有少部分的net发生了变化\n如果HPWL增量，说明新的placement是更优的结果，采用之；否则，不接受\n\n然后课程提出了用模拟退火的策略来进行改进，即当HPWL增量时，以概率接受新的placement, 其中是温度变量，初始值设置的比较大，从而使较接近1，然后随着优化的过程逐渐减小。模拟退火的思想不在此详述，可参考Simulated annealing - Wikipedia.\n\n课程视频还展示了一个动画，这里只有一个截图了：\n\n其中每个点的颜色代表这个grid上的net congestion情况，如果有个net的boundary box占据了这个grid，那么它的congestion就是，随着退火过程的进行，最后congestion变得较少较均匀，不再出现像上图(初始值)这样的有一大片congestion区域的情况。\nQuadratic Wirelength Model一种不同于HPWL的距离。对一个连接个点的net，将其转化为个2-point sub-nets. 记subnet i的欧氏距离为，则对于整个net\n\n\\text{Quadratic Wirelength} =\\alpha\\sum_{i\\in \\text{subnets}}[E(i)]^2其中是一个权重系数，一般取(这样当时).\n\n课程对上图的示例进行了演示。可以看到x轴方向和y轴方向的变量没有乘积项，因此可以分开进行优化。优化的办法很简单，就是对所有变量偏导数，令其等于0，然后解方程组。\n\n\n这个方程组的两个矩阵都是比较容易获取的。首先建立矩阵, 如果gate i和gate j之前存在权重为的连线，那么；然后建立，对于非对角线元素，，对于对角线元素，等于第i行的和+连接pad和gate i的所有连线的权重和：\n\n而的建立也非常简单（对于, 的建立也是类似的）：\n\n这个方程组看上去很恐怖（如果gates的数量很大，方阵A也会变得很大），但是课程指出方阵A具有对称，对角线占优，系数，半正定的性质，因此存在比较好的迭代解法：\n\n由于其对角占优，之前上课学过（但现在又全部忘掉的）Jacobi迭代法和Gauss-Seidel迭代法是可以使用的。关于方程组数值解的迭代法可以参考线性方程组-迭代法 2：Jacobi迭代和Gauss-Seidel迭代 - 知乎。\nRecursive Partitioning\n如果只执行一次quadratic place, 结果可能如上图的左一所示，gates都集中在chip的中间，这样的分布太过不均衡，chip空间利用率低，且容易产生congestion. 解决方法就是进行Recursive Partitioning，将gates分配到chip的不同block中。\n过程是这样子的（以x方向的partition举例），对上一次place的结果进行排序，靠左的gates分配到chip的左半部分，其他分到右半部分：\n\n对于左半部分的子问题，除了被分到这个部分的gates之外，其他的gates和pads都被移到区域边缘且被视为pads: \n\n在y方向上也可做类似的partition: \n\n","categories":["Learning"],"tags":["EDA"]},{"title":"cs143-环境搭建","url":"/Learning/cs143-%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","content":"今天开始自学编译原理，选的课是斯坦福的CS143，先配环境。\n\n虚拟机：VMware\n操作系统：Ubuntu 22.04.1 LTS\n\n安装的步骤参考课程提供的指引Installing Directly on Linux | SOE.YCSCS1 | edX.\n问题更新了PATH，系统仍提示找不到spim程序。\n解决参考了Stanford Compiler 实验环境配置（续） | Doraemonzzz：\n\n这是因为我们在64位系统下运行32位程序，为了运行32位程序，我们需要进行如下配置：\nsudo dpkg --add-architecture i386sudo apt-get updatesudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386\n\n测试参考Getting Started with the VM | SOE.YCSCS1 | edX，在bash中执行命令：\ncp /usr/class/cs143/examples/hello_world.cl .coolc hello_world.clspim hello_world.s\n输出：\nSPIM Version 6.5 of January 4, 2003Copyright 1990-2003 by James R. Larus (larus@cs.wisc.edu).All Rights Reserved.See the file README for a full copyright notice.Loaded: ../lib/trap.handlerHello, World.COOL program successfully executed","categories":["Learning"],"tags":["Compiler"]},{"title":"Logic to Layout Week 1","url":"/Learning/Logic-to-Layout-Week-1/","content":"又开一个坑。课程是UIUC的VLSI CAD Part I:Logic. Week 1就讲了一点布尔代数的内容。\nBasics这一节课只讲了Shannon Expansion：\n\nF(x_1,x_2,\\dots,x_n)=x_i\\cdot F_{x_i}+x_i^{'}\\cdot F_{x_i'}其中\n\nF_{x_i}=F(x_1,x_2,\\dots,x_i=1,\\dots,x_n) \\\\\nF_{x_i'}=F(x_1,x_2,\\dots,x_i=0,\\dots,x_n)Boolean Difference从一元实函数的导数定义出发：\n\n\\dfrac{df}{dx}=\\dfrac{f(x+\\delta)-f(x)}{\\delta}Boolean Derivatives指在某个参数分别取0和1时，函数值是否不同：\n\n\\dfrac{\\partial f}{\\partial x}=f_x\\oplus f_{x'}一些性质：\n\n对不同变量求导数可以交换次序：\n导数的异或是异或的导数：\n\n但是对于与运算和或运算不满足，比较繁琐：\n\n\\begin{aligned}\n& \\frac{\\partial}{\\partial x}(f \\bullet g)=\\left[f \\bullet \\frac{\\partial g}{\\partial x}\\right] \\oplus\\left[g \\bullet \\frac{\\partial f}{\\partial x}\\right] \\oplus\\left[\\frac{\\partial f}{\\partial x} \\bullet \\frac{\\partial g}{\\partial x}\\right] \\\\\n& \\frac{\\partial}{\\partial x}(f+g)=\\left[\\bar{f} \\bullet \\frac{\\partial g}{\\partial x}\\right] \\oplus\\left[\\bar{g} \\bullet \\frac{\\partial f}{\\partial x}\\right] \\oplus\\left[\\frac{\\partial f}{\\partial x} \\bullet \\frac{\\partial g}{\\partial x}\\right]\n\\end{aligned}Quantification Operators对给出了两个函数的定义：\n\n全称量化(Universal Quantification): \n存在量化(Existential Quantification): \n\nNetwork Repair利用全称量化来修复网络，用多路选择器来取代损坏的逻辑门，然后和正常的网络做exnor运算：\n\n得到新函数，求令的，即可得到多路选择器的实际功能。\nRecursive Tautology and URP Implementation问题：如何判断一个布尔代数式子是否为重言式。\n思路：\n\n更好的布尔代数表达法(Cube List)，用来代替卡诺图\n拆分成子式，子式也是重言式，递归求解\n\nCube List要点：\n\n布尔代数式的形式是sum of products\n每个product用一个cube来表示，形如[xx, xx, xx]\n每个变量（比如，）在[]中拥有一个2-bit slot\n01代表这个product里面的变量是\n10代表变量是\n11代表变量不存在于这个product\n\n\n然后这些cube纵向堆叠成list\n\n\n\nUnate Function铺垫的定义。如果一个sum of product式，它的任意变量（比如）都只以或者的形式出现，那就说他是unate，否则是binate. \n\nf is positive unate in var x — if changing x 0-&gt;1 keeps f constant or makes f: 0-&gt;1\nf is negative unate in var x — if changing x 0-&gt;1 keeps f constant or makes f: 1-&gt;0\n\n检查一个式子是不是unate，用cube list是很直观的：\nTautology Checking\nF\\text{ is a tautology} \\iff F_x \\text{ is a tautology and } F_{x'}\\text{ is also a tautology}依次判断：\n\nRule1: 如果cube list含有一个cube，里面的变量全为11，那么这个式子是重言式\nRule3: 如果式子里存在的情况，那么这个式子是重言式\nRule2: 如果式子是unate，且不含有变量全为11的cube，那么这个式子不是重言式\n\n如果不能马上判断，那么寻找一个变量：\n\nPick binate var with most product terms dependent on it (Why? Simplify more cubes)\nIf a tie, pick var with minimum | true var - complement var | (L-R subtree balance)\n\n然后递归地检查两个子式是否为重言式。\n","categories":["Learning"],"tags":["EDA"]},{"title":"VLSI Physical Design - Partition","url":"/Learning/PD-Partition/","content":"很久没有再更新UIUC的Logic to Layout了，也不准备再继续更新下去，因为layout的部分我打算看书学习了，感觉看书的速度应该会比看视频快些。书本选取的是Andrew B. Kahng等人所著的VLSI Physical Design: From Graph Partitioning to Timing Closure. 书本从第二章开始，根据Paritioning -&gt; Chip Planning -&gt; Placement -&gt; Routing的顺序来展开，和比较常见的flow的顺序一致，最后补充Timing的内容。\n第一章讲的是一些比较基础的概念，这里摘录一部分。图论的：\n\n超边（Hyperedge）：连接2个或以上顶点的边。net可能连接2个以上的pin，因此超边比连接两个顶点的边更符合net实际情况。\n超图（Hypergraph）：边集里面的边是超边的图。\n直线最小生成树（RMST，rectilinear minimum spanning tree）：最小生成树，但是曼哈顿距离。\n斯坦纳树（Steiner Tree）：听过但没了解过，以后再来补充。\n\nEDA的：\n\nComponent：电路的基本功能元件，比如晶体管/电容\n\nModule：component的集合。\n\nBlock：Module with shape.\n\nCell：逻辑和功能的基本元件，比如AND gate. \n\n我参加的比赛里面netlist不会指明哪种component，只有library里的standard cell和macro, 所以我个人理解Physical Design里面更多时候谈到的是cell. \n\n\nStandard Cell：带有确定的逻辑功能的cell，高度（不是3d意义上的，而是2d）一般是行高的整数倍，place的时候按行对齐。\n\nMacro (cell)：逻辑尚未确定的cell。也就是说逻辑可以很复杂，可以由很多standard cell组成，因此面积会比较大。\n\n一般Macro和Block会混谈。\n\n\nPin：引脚\n\nvia：通孔\n\n\nPartitioning就是指把顶点集划分成为多个子集。\n\n划分仅仅是一种手段而已，目的可以非常不同，因此优化的目标也可以非常不同。书中是将它作为层次化设计和降低集成电路复杂度的手段来使用，在一个2D的平面上分开几个大的区域（Block），block之间的连接尽量地简化，那么设计人员只需负责自己负责的block就好了。\n但是在我参加的比赛中，3D Circuit被分为两个die，所有的cell/macro必须物理地分到两个die上去，一切以最后的total hpwl为准，因此两个die之间的连接并不总是越少越好。\n\n优化目标按照书上的划分目的，自然是最小化cut edges set的权重\n\n\\sum_{e\\in\\Phi}w(e),\\ \\Phi\\text{ is the cut set.}如果划分得到子集非常不平衡，某些子集只有少数几个cell，似乎可以很好地最小化目标，但这没有达到划分的目的，因此还需要约束子集之间的大小关系，使它们的面积比较接近。\nKernighan-Lin Algorithm算法的输入是一个网表；输出一个划分，将划分为两个大小相等的子集，优化目标是割集的权重。KL算法基于迭代和交换，并不保证给出最优解。\n\n其实Physical Design的大部分情况都这样。即使某个环节的某个算法强求最优，在全局的目标上也不一定是最优的，因此optimal solution就好。\n\n算法的流程就是，对一个划分，每一轮尽力找出一些交换，如果这些交换减小了cut size，就确认进行这些交换然后下一轮。如果尽力了仍然不能减少cut size，那么算法结束。\n在一个轮次中，算法寻找一个交换的序列来执行。cell a和cell b的交换被加入序列后，它们就不允许在后续的交换中出现（fixed），以防循环。这样，算法每次寻找一个最大程度上减小cut size（最大化收益gain）的交换，放入序列之后将他们fix，更新状态，然后寻找继续寻找下一个交换。\n那么收益怎么计算呢？算法要求首先计算将一个节点v从当前子集移动到另一子集的引起的变化​，其被定义为（与v相连的割边权重和） - （与v相连的非割边权重和），因为移动之后，此前的割边就从割集中被去除，而非割边成为了割边。\n那么一对交换的收益就是\n\n\\Delta g(a,b)=D(a)+D(b)-2w(a,b)减去的部分是被重复计算的边权重。整个算法的过程：\n\n算法可以做扩展使得其可以应用于不平衡划分、节点权重不等、多路划分等情况，这里不展开。\nFiduccia-Mattheyses (FM) Algorithm对KL算法进行了如下改进：\n\n不再基于交换，而是基于一个节点的移动。\n\n交换增益被移动增益取代，移动增益被定义为（在v所在的分区内仅连接v的割边权重和）-（连接v的非割边权重和）。\n天然地适合不平衡划分。\n\n\n在挑选加入序列的移动时增加约束条件，若移动发生后满足\n\nr\\cdot area(V)-area_{max}(V)\\le area(A)\\le r\\cdot area(v)+area_{max}(V)（称为平衡条件），移动才会被采纳。\n\nB. Krishnamurthy提出了critical net的概念，简化了FM的计算，但是原理并未改变，此处不展开。\n\n\n后面还有提到FPGA的partition问题，由于我对FPGA了解不多所以看不太懂，这里也先不展开了。\n","categories":["Learning"],"tags":["EDA"]},{"title":"CUDA-C 学习笔记：执行模型","url":"/Learning/cuda-chapter3/","content":"上一个章节提到，可以通过改变grid和block的形状来获取更好的性能，书中提供的例子是直接比较各个config，选更好的那个。但如果想要更好的方法来指导我们设计这些config，我们就必须从硬件以及线程（束）调度的角度更加深入地了解CUDA. \nThe Fermi ArchitectureFermi架构是第一个完整的GPU架构，n卡架构的老祖宗，而且也相对简单。\n\n其中的结构\n\n被称为流处理器(stream multiprocessor, SM) ，上面有若干计算资源，比如：\n\ncuda 核\n共享内存/一级缓存\n寄存器堆\nLoad/Store单元\n特殊功能单元\n线程束调度器\nBlock内每32个线程被划分为一个线程束（warp）\n\n\n\n执行模型保证：\n\n当block被分配到SM上之后，就不可能重新分配到其他SM上运行\n\n当block被分配到SM上之后，块上的线程独占的资源：\n\n指令地址计数器\n寄存器上下文等\n\n只有到block结束生命周期时才释放，因此切换线程的开销很低。\n\n\nSIMT（单指令多线程）字面意思就是一个指令在多个线程上执行，具体地说，“多个线程”指的是同一个线程束上的线程。每次，线程束调度器选取一个线程束，这个线程束中的线程此前都执行到同一个指令地址，此刻开始它们同步地执行下一条指令，直至线程束被换下。\n如果需要执行分支指令，而且线程束中存在某些线程的分支跳转结果不同，如if(1)和if(0)，那么（假设先执行1）在执行if(1)线程的指令时，if(0)的线程将空转，执行完1的分支后，0的分支反之亦然，这保证了分支结束后的指令能够同步执行。\n也因为这样，同一个线程束内最好不要产生分支，这会造成较大的延迟。\nThe Kepler Architecture开普勒架构出现在费米架构之后。除了计算资源变多之外，结构上主要的不同在于：\n\n费米架构的grids组成单队列等待分配，但开普勒架构可以有多个队列，因此开普勒架构在核函数之间也可以存在并行（Hyper-Q）\n费米架构的kernel必须从host启动，但开普勒架构的kernel可以自行启动新的kernel（dynamic parallelism）\n\n","categories":["Learning"],"tags":["cuda"]},{"title":"ePlace","url":"/Paper-reading/ePlace/","content":"\nGossip: 好久没有更新了，主要是陷入了毕设的苦战，经常没空看书。和组里老哥接上线并且联系到同年的两位老哥之后，更加感觉自己无比的废物。但好在毕设已经接近尾声，我可以准备下一阶段的工作了。\n\n这篇blog是我阅读ePlace: Electrostatics-Based Placement Using Fast Fourier Transform and Nesterov’s Method所做的笔记，但主要是为了阅读另一篇文章服务的，所以我不会读完再更，而是写到哪里更到哪里。\nEssential Concepts超图: 是节点的集合，指movable cells和fixed macros；是net的集合，而net不是传统意义上的边，它可能连接多个cell，所以E是set of hyperedges；是placement region.\nHPWL: 围住net的最小矩形的半周长，ePlace的主要优化目标。\n\nHPWL_e(\\mathbf{v})=\\max _{i, j \\in e}\\left|x_i-x_j\\right|+\\max _{i, j \\in e}\\left|y_i-y_j\\right|显然这是不可微的，文中提到的近似包括Log-Sum-Exp(LSE):\n\nW_e(\\mathbf{v})=\\gamma(\\ln \\sum_{i\\in e}\\exp (\\dfrac{x_i}{\\gamma}) + \\ln \\sum_{i\\in e}\\exp (\\dfrac{-x_i}{\\gamma}))其中是包含个连接点的net, 而是控制近似精度的超参数，它使得LSE对HPWL的误差在范围内；以及Weighted Average(WA):\n\nW_e(\\mathbf{v})=(\\dfrac{\\sum_{i\\in e}x_i\\exp (x_i/\\gamma)}{\\sum_{i\\in e}\\exp (x_i/\\gamma)}-\\dfrac{\\sum_{i\\in e}x_i\\exp (-x_i/\\gamma)}{\\sum_{i\\in e}\\exp (-x_i/\\gamma)})其误差在范围内。\n密度：将均匀分解为的网格，对其中的一个网格，定义其密度为\n\n\\rho_b(\\mathbf{v})=\\sum_{i \\in V} l_x(b, i) l_y(b, i)对节点而言，是其与的在x方向上的overlap，同理。因此有密度上的约束条件：\n\n\\min _{\\mathbf{v}} H P W L(\\mathbf{v}) \\text { s.t. } \\rho_b(\\mathbf{v}) \\leq \\rho_t, \\forall b \\in B由于可能非常大非常麻烦，因此需要一个等价的全局约束来替代它，并被加入优化目标中：\n\n\\min_{\\mathbf{v}}f(\\mathbf{v})=W(\\mathbf{v})+\\lambda N(v)eDensity\nGossip: 我也想要这么大个脑洞啊，说到底我之前做的生信炼丹也是一种抽象，就是将生物信息问题抽象成自然语言序列的问题，进而用NLP的方法去处理，但是倒过来的话我感觉用其他领域的概念去对计算机领域的概念进行建模有点困难，主要是其他的知识也没有储备很多，所以真的需要广泛涉猎……\n\n这一段是这篇文章的核心。在网格的边界处，上面提到的密度同样是不可微的，因此需要近似。\n\n密度抽象\n\n最关键的抽象在于，两个cell应该以什么方式进行排斥？这篇文章的想法是按照库仑斥力的方式。\n密度惩罚项被抽象为电势能(见上图)，其中是电荷所在位置的电势，对于多个点电荷产生的电场，其某个位置的电势即各点电荷在此产生的电势之和。\n根据高斯定理，网格内的电势分布的梯度即是电场分布：\n\n\\mathbf{\\xi}(x,y) = -\\nabla\\psi(x,y)这样优化目标就变得可微了。但是，在这个抽象里cell和macro的实例都被抽象成正点电荷，因而所有点电荷都在斥力的作用下向网格边缘扩散，还需要其他的约束条件：\n\n根据泊松定理，电荷密度是电场分布的散度：\\rho(x,y)=\\nabla\\cdot\\mathbf{\\xi}(x,y)=-\\nabla\\cdot\\nabla\\psi(x,y)\n去除电场直流分量，即令电势分布加上一个常数，使得\\iint_R\\psi(x,y)=0这也使得电场中某些地方的电荷密度为负数，即产生了将正点电荷向此处吸引的趋势，而且从泊松定理有.\n点电荷扩散至在网格边缘处必须停下，不应再向外扩散，记边缘处的法向量为，则：\\hat{\\mathbf{n}}\\cdot\\nabla\\psi(x,y)=\\mathbf{0}, (x,y)\\in \\partial R\n\nfiller insertion好怪啊，这又是一种反过来抑制正点电荷之间斥力，使得cells spread到所有可放置区域的办法。它的想法是通过插入一些的可以移动但不能连线的filler cells，迫使实际放置的movable cells向中间聚集，这些fillers占据的总面积受到\nA_{fc}=\\rho_t A_{ws}-A_m约束。除此之外，还可以指定一些固定的区域为dark nodes，它们虽然占据空间，但不计入上述的约束中。在完成placement之后，这些填充物都需要去除。\n\n在插入之后，计算电势分布时应该考虑超集，然后在梯度回传时只更新即可。（未完待续……）\n","categories":["Paper-reading"],"tags":["EDA"]},{"title":"eplace-ms","url":"/Paper-reading/eplace-ms/","content":"\n论文以及图片来源：ePlace-MS: Electrostatics-Based Placement for Mixed-Size Circuits | IEEE Journals &amp; Magazine | IEEE Xplore\n我想通过读这篇文章来学习macro legalization，因此可能不会写完。\n\nWorkFlow\n分为五个阶段，m代表mix-size circuits，c代表cell. 在初始化(mIP)后，对cells和macros进行place，原理和eplace是一样的；然后对macros进行legalize(mLG)，将macros固定下来；再做一次对cell的gp之后交给dp。\nmLGmLG输入是mGP输出的解，并假定它的质量是不错的，因此只在小范围内直接通过模拟退火算法移动macros. \n\n模拟退化算法的介绍可以参考本站的Logic to Layout Week 5 | diri! (diri-lin.top)或者其他网络内容。\n\n\nmLG的优化目标是\n\nf_{mLG}(v)=HPWL(v)+\\mu_DD(v)+\\mu_OO_m(v)\nHPWL即总线长\n是被macros覆盖的cell的总面积\n惩罚系数在每一轮的开始被初始化为，理由是在cGP和cDP中也将被转化为线长\n\n\n是macros的overlap\n惩罚系数在第一轮的开始被初始化为，此后每一轮被乘以.\n\n\n\n模拟退火算法是这样建模的(j, k分别代表mLG和SA循环的轮数)：\n\n是一次移动的HPWL增量（正的，说明HPWL变差了）\n温度\n移动被接受的条件是，以均匀分布获取的随机变量\n是这样定义的：\n，这意味着在SA内循环的第一轮，50%的可能被接受的HPWL增量是3%\n线性地递减到\n\n\n移动的搜索半径是这样定义的：\n\n没说有啥用……尬住了\n\n\n\n","categories":["Paper-reading"],"tags":["EDA"]},{"title":"CUDA-C 学习笔记","url":"/Learning/cuda/","content":"猛摆烂，又开一坑。看的书是Professional CUDA C Programming, 然后参考谭升的博客（在CUDA-C学习笔记系列中简称“博客”），我觉得肯定比我讲得好得多，因此我写的只供自己记录用。在这篇发布的时候，我只看到了Chapter3, 因此可能很多理解尚需完善。\n\n题外话，我觉得一上来就整些高屋建瓴的话其实没什么用，这些话懂得自然懂，不懂的该学还是要学，直接开干就完事了。\n\nChapter 1: Heterogeneous Parallel Computing with CUDA使用CPU+GPU的异构方式来处理并行计算任务：\n\n程序猿要做的事情是：\n\n在主机(host, CPU)上编写并运行程序，准备并行计算的指令和数据\n将并行计算数据通过总线发送到设备(device, GPU)上\n调用核函数，让设备进行并行计算\n将计算结果下载回主机\n\n为什么要做大规模的并行计算，为什么不用CPU做大规模的并行计算而用GPU，这里不再赘述（可以参考博客）。但是，这说明设备（的架构）是很重要的，因此在编写并行计算程序的时候，需要根据GPU的架构和性质尽量压榨其并行能力。\n最后，nvidia的显卡被广泛应用于高性能计算领域，而CUDA是建立在nvidia GPU上的平台，提供了大量API供程序猿操作设备完成计算，这就是需要学习CUDA的原因。\nChapter 2: CUDA Programming Model这章讲CUDA的编程模型。CUDA-C的程序大概这样：\n\n主进程运行在主机上，并行计算的数据准备好后：\n\n将并行计算数据通过总线发送到设备(device, GPU)上\n调用核函数，让设备进行并行计算\n\n这时主进程将立刻去做其他事（异步）。计算结束后，将计算结果下载回主机。这三件事情是和GPU相关的，因此需要用到CUDA runtime API. \n在设备之间复制数据将数据发送到设备上，其实就是在设备上分配一块内存（malloc），然后将主机上的数据复制过去（memcpy），CUDA-C中进行这两个操作的API和C语言很像，但稍有不同：\ncudaError_t cudaMalloc(void **devPtr,size_t nByte);cudaError_t cudaMemcpy(void * dst,const void * src,size_t count, cudaMemcpyKind kind)\n比如为长度为1024个元素的浮点数组float *data分配，执行的语句是：\ncuda cudaMalloc(&amp;data, 1024*sizeof(float));\n因为需要将设备上的内存地址写入data变量，所以这里需要传入它的指针。\ncudaMemcpy的前面三个参数无需赘述，最后一个枚举变量参数指明了复制数据的方向：\n\ncudaMemcpyHostToHost\ncudaMemcpyHostToDevice\ncudaMemcpyDeviceToHost\ncudaMemcpyDeviceToDevice\n\n比如将主机上长度为1024的浮点数组h_data的数据复制到设备上浮点数组d_data中：\n\n主机上的空间用h_开头，而设备上的用d_，书中约定如此，这里也照搬。\n\ncudaMemcpy(d_data, h_data, 1024 * sizeof(float), cudaMemcpyHostToDevice);\ncudaMemcpy关系到主机与设备的数据交换，因此隐式地进行了同步。如果需要显式的同步，需要调用cudaDeviceSynchronize(). 在设备上申请到的内存最后要调用cudaFree(void *ptr)进行释放.\n最后说下返回类型cudaError_t，如果函数成功执行，则返回cudaSuccess，否则返回对应的错误类型，可以使用函数char* cudaGetErrorString(cudaError_t error)来将错误类型转化为方便阅读的字符串。\n核函数（kernel）核函数就是在设备上运行的函数。有必要先看一下CUDA编程模型提供的线程层次抽象：\n\n核函数在在设备上的一个网格（Grid）里面执行，网格由块（Block）组成，可以看做三维的块数组，而块又可以看成线程的三维数组。\n\n虽然图上展示的是二维。而且物理上都是一维的。\n\n然后是内存抽象：\n\n除了全局内存之外，块内存在共享内存，可以被块内的线程访问。\n\n但就我看到前三章的部分来说，都在按照线程的索引计算位于全局内存中数组的位置，没咋看到用共享内存。\n\n然后才是核函数的定义和调用。核函数是这样被调用的：\nfunction_name&lt;&lt;&lt;grid, block&gt;&gt;&gt;(argument_list);\n其中grid可以是整数，也可以是一个dim3结构体，指明了这次调用的网格是什么形状的三维块数组，同理block也指明了这次调用的网格是什么形状的三维线程数组。\n核函数在定义时的函数头是这样的：\nRETURN_TYPE QUALIFIER function_name(argument_list);\n其中限定符QUALIFIER指明了函数可以在什么样的设备上执行：\n\n\n\n\n限定符\n执行\n调用\n备注\n\n\n\n\n__global__\n设备端执行\n可以从主机调用也可以从计算能力3以上的设备调用\n必须有一个void的返回类型\n\n\n__device__\n设备端执行\n设备端调用\n\n\n\n__host__\n主机端执行\n主机调用\n可以省略\n\n\n\n\n在定义函数的时候可以访问这些被预定义的变量：\n\nblockIdx 当前线程所在的块，在网格中的三维索引\nthreadIdx 当前线程在块中的三维索引\ngridDim 网格的形状，如果在调用时直接传入一个整数g，则为(g,1,1)\nblockDim 块的形状\n\n\n然后就可以根据这些信息来计算某一线程应该处理数组的哪个部分之类的……\n\n核函数调用计时两种方法。一种是记录调用前的CPU时间戳，调用执行结束后主机显式同步，然后记录执行结束的CPU时间戳。\niStart = cpuSecond(); sumMatrixOnGPU2D &lt;&lt;&lt; grid, block &gt;&gt;&gt;(d_MatA, d_MatB, d_MatC, nx, ny);cudaDeviceSynchronize(); iElaps = cpuSecond() - iStart;\n另一种是查看nvidia的工具nvprof：\n$ nvprof ./sumArraysOnGPU-timer./sumArraysOnGPU-timer Starting... Using Device 0: Tesla M2070 ==17770== NVPROF is profiling process 17770, command: ./sumArraysOnGPU-timer # 程序输出balabala==17770== Profiling application: ./sumArraysOnGPU-timer ==17770== Profiling result: Time(%) Time Calls Avg Min Max Name 70.35% 52.667ms 3 17.556ms 17.415ms 17.800ms [CUDA memcpy HtoD] 25.77% 19.291ms 1 19.291ms 19.291ms 19.291ms [CUDA memcpy DtoH] 3.88% 2.9024ms 1 2.9024ms 2.9024ms 2.9024ms sumArraysOnGPU (float*, float*, int)\n后者更加准确，但前者可以在runtime得到报告。\n然后书本举了几个例子，使用不同的grid shape和block shape处理相同矩阵加法问题，引出：\n\n不同的config之间存在运行时间的差异（需要上述测量手段）\n如何寻找更好的config？靠盲猜太不科学，也浪费很多时间和计算资源。\nCUDA程序必须根据设备的硬件特性编写\n\n\n\n然后给了一堆查runtime和nvidia-smi的查信息方法，这里就不赘述了。\n其实我这个东西写到现在非常摆，基本没怎么沾硬件，但既然要根据硬件特性来编写，那么更深入地了解n卡是逃不掉的。\n","categories":["Learning"],"tags":["cuda"]},{"title":"开学","url":"/Gossip/%E5%BC%80%E5%AD%A6/","content":"好久没有管过我这个鸟个人主页了。从去年12月到现在，我一直在申请留学，到现在为止我的申请季已经结束了。\n明天就要回shit了。回想起来，我还没有过上快乐的大学生活过。最后的几个月也没什么好折腾的，调调参，看看番，吃喝玩乐，就这样过去就好。\n但是大学本科没有好好读书真是遗憾哪。所以在摸鱼之余我也想学点东西，首先是我没有选修的编译原理，准备有空看看虎书；还有就是boy♂推荐的并行编程。\n嗯，希望最后半年能够平淡而精彩捏。\n","categories":["Gossip"]},{"title":"思考人生","url":"/Gossip/%E6%80%9D%E8%80%83%E4%BA%BA%E7%94%9F/","content":"最近一有空就只能发呆，然后游戏也腻了，天天打没意思。决定在读博之前思考下人生，想想入学之前我能做些什么来使我更好地应对接下来的挑战。有个说法是work-life balance，就从学术和生活这两方面入手吧。\n学术虽已成为历史，拙劣的本科经历还是提醒我要策马向前。正是：\n\n悟已往之不谏，知来者之可追。\n\n目前我了解到的两条工作路径：\n\n阅读已有论文，进行积淀 -&gt; 产生新问题 或 已有问题产生新方案 -&gt; 验证 （来自本科科研经历）\n参加竞赛 -&gt; 面向赛题引领学习，提出解决方案（来自cuhk笔试的EDAthon题目）\n\n之前多少接触过部分内容，遇到一些困难：\n\n面试之前没有读懂教授的论文\n\n主要的原因看来是EDA基础知识的缺乏，使得我一碰到相关概念基本上就投降。教授：\n\n Actually, most most of the incoming students have zero knowledge in EDA.\n\n除此之外，虽然做机器学习的时候还是读过一些论文的，但是没有养成很良好的阅读习惯，如归纳笔记等；而且由于不再继续做生物信息深度学习，我很久没有读过新的论文了。\n\n\n\n很少经过竞赛这种限时的压力测试的考验\n\nC++用得太少了，之前主要还是写C和Python\n\n\n其实并没有很多时间让我去学很多东西，而且我现在处在本科的结束阶段，也很累了，不可能像一个超人一样在学习，姑且定下两个方面的学习目标：\n\nEDA基础知识，从Coursera上：\nVLSI CAD Part I: Logic （学过一点，快速通过，就不写程序了）\nVLSI CAD Part II: Layout\n\n\nC++\n\n生活总的来说，我对本科阶段的生活还有身体健康的管理是非常不满意的。我感觉大概有以下几个方面需要做得更好：\n\n进行工作和业余生活的计划的能力\n现在的问题主要体现在不能很好地划分工作和生活的界限，该工作的时候想要摸鱼摆烂，该享受生活的时候想着工作还没有完成不能尽兴\n而且在没有计划的前提下，经常需要花时间来思考下一步要做什么\n不能规律作息也对我的身体造成伤害\n\n\n做饭\n本来打算去欧洲的话这可能是一个必备技能，现在去香港这个可以放宽些\n也算是为寻求交往储备的技能？\n\n\n学会玩乐和享受\n比如我现在，面对一大块的时间和足够的零花钱，我不知道怎么去享受它们。我不知道深圳有哪里好玩，也不知道花一点小钱来享受是不是“可以的”\n对比龙大王这样的生活，我的生活简直就是郭楠的悲哀。我觉得享受生活，享受人生，享受自己的劳动成果，可能都是很大一部分男生应该学会而没有学会，甚至被周围环境的规训阻止获得的技能\n\n\n学会交友\n太过社恐，比较难交到新的朋友，特别是和异性朋友的沟通非常困难\n\n\n\n这已经有太多的事情需要去做了，先就这么多吧。希望在这个短暂的间隙我能变得更好，然后走上科研的正轨。\n","categories":["Gossip"]},{"title":"申请季总结","url":"/Gossip/%E7%94%B3%E8%AF%B7%E5%AD%A3%E6%80%BB%E7%BB%93/","content":"\n\n我又摆烂了好长的一段时间，cs143的课我只配了个环境就又搁置了。虽然我确实是个很懒的人，但这次确实是有很重要的事情所以把课放下，而且很有可能就变成一个兴趣爱好来学习了。在讲我的流水账故事之前先说结果：去cuhk了。\n重新整理于2023.6.8\n\n\nTimeline\n大二结束 2021.9\n\n出于不可明说的原因，放弃保研转向留学\n\n\n大三秋季学期\n\n第一段科研，分布式机器学习相关\n\n严格来说不能说是“一段”，这是作为计算机体系结构实验课的替代，参加了一部分实验。\n遇到了God·Wcy.\n\n\n第二段科研，生物信息学的机器学习相关，指导老师是陈俊杰老师\n\n非常感谢陈老师在科研过程中对我的指导，这也是我后来毕设做的内容。\n\n\n\n\n大三夏季学期\n\n语言\n\n\n大四秋季学期\n\n开始申请\n\n\n\n申请结果\n\n\n\n学校-项目\n结果\n备注\n\n\n\n\n墨尔本大学-mcs\n录取-小奖\n保底中的保底\n\n\n苏黎世联邦理工-cs msc\n被拒\n和机制有关吧，泥shit有两位爷排在我前面\n\n\n洛桑联邦理工-cs msc\n被拒\n\n\n\n查尔姆斯理工-高性能计算-msc\n录取\n没奖蚌埠了\n\n\nEIT-网络与云计算安全 msc\n录取-半奖\n\n\n\nX-cs 2+3硕博连读\n被拒\n\n\n\n德国亥姆霍兹/萨尔大学-cs phd\n面试被拒\n\n\n\n香港中文大学-cse phd\n录取\n最终去向\n\n\nKAUST-cs ms/phd连读\n放弃面试\n来得太晚了，已承诺cuhk\n\n\nNUS-cs msc\n录取\n6月下offer是认真的吗\n\n\n\n\nGossip\n关于欧洲\n整个过程非常焦虑，看邮箱-&gt;没录取-&gt;加投-&gt;求老师写推荐信-&gt;看邮箱循环\n\n\n关于香港\n全靠God·Wcy和God·Cyz两位爷push我去投，我对自己是一点信心也没有的\n结果后面普信起来了真敢投（普信很重要）\nCUHK第一批的Committee笔面试较简单，但据说提前批比较难\n所有的陶瓷也都真的没有回复，符合我的自我评价，最后是Evan发邮件捞了我\n\n\n关于KAUST\n在我答应了Evan两三天之后，有做分布式机器学习和FPGA的叫兽找我面试，其中一位我关注挺久了，不过他的要求是陶瓷的时候得熟读他的一篇论文并在陶瓷信里附上感想，还在陶瓷阶段的时候我感觉这个花费精力太多了，就先申着msc再说。\n\n\n录取之后\n2023.2.24半夜看球收到Evan邮件，此时面试已经过去很久，我基本已经忘了这事\n一周考虑时间内咨询了很多师友的意见，其中给我解开了疑惑的最重要的意见来自哈深电信学院的崔爱娇老师，然后我就接下了这个offer，我的申请季就这么结束了。\n\n\n\n总结在事情敲定了之后回想，直博真是一件神奇的事情：\n\n我的背景铁定是历史上哈深cs直博香港的所有学生里最差的一个；\n同时我还对EDA have zero knowledge（叫兽原话，但似乎她并不在意）；\n当初驱动我走上留学道路的原因，现在其实已经释然。\n\n如果让我重来一遍，我想要把握住进哈深之前的想法，那就是找工作；但是我随波逐流，已然走上了现在的道路（我到底是干了什么啊我真的不清楚），以后唯有多加努力了。\n","categories":["Gossip"]}]